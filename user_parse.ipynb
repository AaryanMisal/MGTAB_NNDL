{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9738461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "736d6da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1b1c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) For embedding+dimensionality reduction\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "04072f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32fe2a2",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e131d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../Dataset/TwiBot-22\"\n",
    "\n",
    "DATA_DIR = Path(DATA_DIR)\n",
    "# make sure the data directory exists\n",
    "if not DATA_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Data directory {DATA_DIR} does not exist.\")\n",
    "\n",
    "def load_json_records(fname):\n",
    "    \"\"\"Load a JSON file of array- or line- delimited records.\"\"\"\n",
    "    path = DATA_DIR / fname\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        # if the file is a single large JSON array:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            # fallback: one JSON object per line\n",
    "            f.seek(0)\n",
    "            data = [json.loads(line) for line in f]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c706d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dicts = load_json_records('user.json')\n",
    "users_df = pd.DataFrame(user_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebd04cd",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "367dc0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['followers_count', 'following_count', 'tweet_count', 'listed_count'], dtype='object')\n",
      "   followers_count  following_count  tweet_count  listed_count\n",
      "0             7316              215         3098            69\n",
      "1              123             1090         1823             0\n",
      "2                3               62           66             0\n",
      "3              350              577          237             1\n",
      "4              240              297         3713             8\n"
     ]
    }
   ],
   "source": [
    "pm = pd.json_normalize(users_df['public_metrics'])\n",
    "print(pm.columns)\n",
    "print(pm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dcfabcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.concat([users_df.drop('public_metrics',axis=1), pm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c7cda272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['url.urls', 'description.urls', 'description.mentions',\n",
      "       'description.hashtags', 'description.cashtags'],\n",
      "      dtype='object')\n",
      "                                            url.urls  \\\n",
      "0  [{'start': 0, 'end': 23, 'url': 'https://t.co/...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                    description.urls  \\\n",
      "0  [{'start': 41, 'end': 64, 'url': 'https://t.co...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                               description.mentions description.hashtags  \\\n",
      "0                                               NaN                  NaN   \n",
      "1                                               NaN                  NaN   \n",
      "2                                               NaN                  NaN   \n",
      "3  [{'start': 43, 'end': 50, 'username': 'UVA_ID'}]                  NaN   \n",
      "4                                               NaN                  NaN   \n",
      "\n",
      "  description.cashtags  \n",
      "0                  NaN  \n",
      "1                  NaN  \n",
      "2                  NaN  \n",
      "3                  NaN  \n",
      "4                  NaN  \n"
     ]
    }
   ],
   "source": [
    "ent = pd.json_normalize(users_df['entities'])\n",
    "print(ent.columns)\n",
    "print(ent.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "121a3ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.concat([users_df.drop('entities',axis=1), ent], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a34f0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse your created_at as UTC\n",
    "users_df['created_at'] = pd.to_datetime(users_df['created_at'], utc=True)\n",
    "\n",
    "# get “now” in UTC, so it’s also tz-aware\n",
    "now_utc = pd.Timestamp.now(tz='UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "99be197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) account age in days\n",
    "users_df['account_age_days'] = (now_utc - users_df['created_at']).dt.days\n",
    "\n",
    "# 2) tweets per day\n",
    "users_df['tweets_per_day'] = users_df['tweet_count'] / users_df['account_age_days']\n",
    "\n",
    "# # 3) binary flags\n",
    "# users_df['is_verified'] = users_df['verified'].astype(int)\n",
    "# users_df['is_protected'] = users_df['protected'].astype(int)\n",
    "\n",
    "# 4) length of bio\n",
    "# users_df['desc_len'] = users_df['description'].fillna('').str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4ad89176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop created at, description, and verified\n",
    "users_df = users_df.drop(columns=['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82d3db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df['profile_image_url'] = users_df['profile_image_url'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "29199ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['description', 'id', 'location', 'name', 'pinned_tweet_id',\n",
       "       'profile_image_url', 'protected', 'url', 'username', 'verified',\n",
       "       'withheld', 'followers_count', 'following_count', 'tweet_count',\n",
       "       'listed_count', 'url.urls', 'description.urls', 'description.mentions',\n",
       "       'description.hashtags', 'description.cashtags', 'account_age_days',\n",
       "       'tweets_per_day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "449e2de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df['protected'] = users_df['protected'].astype(int)\n",
    "users_df['verified']  = users_df['verified'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bcb888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/6] Concatenating text fields and embedding…\n"
     ]
    }
   ],
   "source": [
    "print(\"[3/6] Concatenating text fields and embedding…\")\n",
    "\n",
    "# combine the three text fields into one string per user\n",
    "def safe_str(x):\n",
    "    return x if isinstance(x, str) else \"\"\n",
    "users_df['text_combo'] = (\n",
    "    users_df['description'].apply(safe_str) + \"  \" +\n",
    "    users_df['name'].apply(safe_str) + \"  \" +\n",
    "    users_df['username'].apply(safe_str) + \"  \" +\n",
    "    users_df['location'].apply(safe_str)\n",
    ")\n",
    "\n",
    "users_df['text_combo'] = users_df['text_combo'].fillna('')\n",
    "users_df = users_df.drop(columns=['description', 'name', 'username', 'location'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2c288038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 19)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8437df",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = users_df.drop(columns=['withheld', 'url.urls', 'description.urls', 'description.mentions', 'description.hashtags', 'description.cashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "03d9a620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'pinned_tweet_id', 'profile_image_url', 'protected', 'url',\n",
       "       'verified', 'followers_count', 'following_count', 'tweet_count',\n",
       "       'listed_count', 'account_age_days', 'tweets_per_day', 'text_combo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac832cb",
   "metadata": {},
   "source": [
    "### Text Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "68f9a3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3907/3907 [1:17:20<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# load a compact, high-quality SentenceTransformer\n",
    "model = SentenceTransformer('all-mpnet-base-v2')  \n",
    "# WHY? mpnet-base gives 768-dim embeddings aligned for sentence similarity.\n",
    "\n",
    "# embed in batches to avoid OOM\n",
    "batch_size = 256\n",
    "texts = users_df['text_combo'].tolist()\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    batch = texts[i:i+batch_size]\n",
    "    embs = model.encode(batch, convert_to_numpy=True, show_progress_bar=False)\n",
    "    embeddings.append(embs)\n",
    "embeddings = np.vstack(embeddings)  \n",
    "# shape = (num_users, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "54c702d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/6] Reducing embeddings to 12 dims with PCA…\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ——— STEP 4: PCA → 8 DIMS ————————————————————————————————\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"[4/6] Reducing embeddings to 12 dims with PCA…\")\n",
    "pca = PCA(n_components=12, random_state=42)\n",
    "text_feats_12 = pca.fit_transform(embeddings)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89caada",
   "metadata": {},
   "source": [
    "### ID Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a8dfdff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] Saved ID/meta mapping to node_meta.json\n"
     ]
    }
   ],
   "source": [
    "id_cols = ['id', 'pinned_tweet_id', 'profile_image_url', 'url']\n",
    "# ensure strings and fill missing pinned_tweet_id with empty string\n",
    "users_df['pinned_tweet_id'] = users_df['pinned_tweet_id'].fillna('').astype(str)\n",
    "users_df['profile_image_url'] = users_df['profile_image_url'].fillna('').astype(str)\n",
    "users_df['url']               = users_df['url'].fillna('').astype(str)\n",
    "users_df['id']                = users_df['id'].astype(str)\n",
    "\n",
    "meta = { col: users_df[col].tolist() for col in id_cols }\n",
    "with open('node_meta.json','w') as f:\n",
    "    json.dump(meta, f)\n",
    "print(f\"[✔] Saved ID/meta mapping to node_meta.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5f8550",
   "metadata": {},
   "source": [
    "### Numeric Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dae5ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    'protected','verified',\n",
    "    'followers_count','following_count','tweet_count','listed_count',\n",
    "    'account_age_days','tweets_per_day'\n",
    "]\n",
    "numeric_feats = users_df[numeric_cols].to_numpy(dtype=float)\n",
    "assert numeric_feats.shape[1] == 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ed540",
   "metadata": {},
   "source": [
    "### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dc670d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/6] Stacking numeric + text feats → (N, 20)…\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ——— STEP 5: STACK & FORM FINAL (num_users × 20) ————————————————————\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"[5/6] Stacking numeric + text feats → (N, 20)…\")\n",
    "final_feats = np.hstack([numeric_feats, text_feats_12])\n",
    "assert final_feats.shape[1] == 20, \"Expected 20 features!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "24939713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/6] Done! Saved property tensor with shape torch.Size([1000000, 20]) to num_properties_tensor.pt\n"
     ]
    }
   ],
   "source": [
    "# convert → torch tensor\n",
    "prop_tensor = torch.tensor(final_feats, dtype=torch.float)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ——— STEP 6: SAVE FOR RGT ————————————————————————————————\n",
    "# -----------------------------------------------------------------------------\n",
    "out_path = 'num_properties_tensor.pt'\n",
    "torch.save(prop_tensor, out_path)\n",
    "print(f\"[6/6] Done! Saved property tensor with shape {prop_tensor.shape} to {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
